{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Diego Homelessness Service Gap Analysis\n",
    "\n",
    "This notebook explores the service gap scoring algorithm used in the San Diego Homelessness Dashboard.\n",
    "We'll analyze different weighting schemes and visualize how they affect the final gap scores.\n",
    "\n",
    "## Service Gap Score Components\n",
    "\n",
    "The current algorithm calculates a score (0-100) based on:\n",
    "1. **Poverty Rate** (0-50 points): Higher poverty increases gap score\n",
    "2. **Population Density** (0-25 points): More people may need more services\n",
    "3. **Service Availability** (0-15 points): Fewer services increase gap score\n",
    "4. **Geographic Access** (0-10 points): Distance to nearest service\n",
    "\n",
    "Higher scores indicate greater need for additional homeless services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from scipy.spatial.distance import cdist\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# Load demographic data\n",
    "acs_data = pd.read_csv('public/data/acs2023_hackathon.csv')\n",
    "print(f\"ACS Data: {len(acs_data)} zip codes\")\n",
    "\n",
    "# Load homeless services\n",
    "with open('public/data/homeless_services_hackathon.json', 'r') as f:\n",
    "    services_data = json.load(f)\n",
    "services_df = pd.DataFrame(services_data)\n",
    "print(f\"Homeless Services: {len(services_df)} locations\")\n",
    "\n",
    "# Load zip code boundaries\n",
    "zip_gdf = gpd.read_file('public/data/sd_zipcodes.geojson')\n",
    "print(f\"Zip Code Boundaries: {len(zip_gdf)} polygons\")\n",
    "\n",
    "# Process demographic data\n",
    "acs_processed = acs_data.copy()\n",
    "acs_processed['zipCode'] = acs_processed['Zip Code'].astype(str)\n",
    "acs_processed['population'] = acs_processed['Population'].fillna(0)\n",
    "acs_processed['povertyPopulation'] = acs_processed['Population in Poverty'].fillna(0)\n",
    "acs_processed['povertyRate'] = (\n",
    "    acs_processed['povertyPopulation'] / acs_processed['population'] * 100\n",
    ").fillna(0)\n",
    "acs_processed['medianIncome'] = acs_processed['Median Income'].fillna(0)\n",
    "\n",
    "# Process services data\n",
    "services_clean = services_df[\n",
    "    (services_df['latitude'].notna()) & \n",
    "    (services_df['longitude'].notna())\n",
    "].copy()\n",
    "services_clean['lat'] = pd.to_numeric(services_clean['latitude'], errors='coerce')\n",
    "services_clean['lng'] = pd.to_numeric(services_clean['longitude'], errors='coerce')\n",
    "services_clean = services_clean.dropna(subset=['lat', 'lng'])\n",
    "\n",
    "print(f\"\\nProcessed:\")\n",
    "print(f\"- Demographics: {len(acs_processed)} zip codes\")\n",
    "print(f\"- Services: {len(services_clean)} valid locations\")\n",
    "print(f\"- Poverty rate range: {acs_processed['povertyRate'].min():.1f}% - {acs_processed['povertyRate'].max():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Service Gap Algorithm\n",
    "\n",
    "Let's implement the current algorithm from the JavaScript code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gap_score_current(poverty_rate, population, service_count, nearest_distance):\n",
    "    \"\"\"\n",
    "    Current algorithm from the JavaScript implementation\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # Poverty component (0-50 points)\n",
    "    score += min(poverty_rate * 2, 50)\n",
    "    \n",
    "    # Population component (0-25 points)\n",
    "    population_score = min((population / 1000) * 5, 25)\n",
    "    score += population_score\n",
    "    \n",
    "    # Service availability component (0-15 points)\n",
    "    service_score = max(15 - (service_count * 3), 0)\n",
    "    score += service_score\n",
    "    \n",
    "    # Distance component (0-10 points)\n",
    "    if nearest_distance is not None:\n",
    "        distance_score = min(nearest_distance * 2, 10)\n",
    "        score += distance_score\n",
    "    else:\n",
    "        score += 10\n",
    "    \n",
    "    return min(score, 100)\n",
    "\n",
    "# Test the function\n",
    "test_score = calculate_gap_score_current(25.0, 50000, 2, 3.5)\n",
    "print(f\"Test gap score: {test_score:.1f}\")\n",
    "\n",
    "# Break down the components\n",
    "print(\"\\nScore breakdown for test case:\")\n",
    "print(f\"- Poverty (25% rate): {min(25 * 2, 50):.1f} points\")\n",
    "print(f\"- Population (50k): {min((50000 / 1000) * 5, 25):.1f} points\")\n",
    "print(f\"- Services (2 count): {max(15 - (2 * 3), 0):.1f} points\")\n",
    "print(f\"- Distance (3.5 miles): {min(3.5 * 2, 10):.1f} points\")\n",
    "print(f\"- Total: {test_score:.1f}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Service Counts and Distances\n",
    "\n",
    "For each zip code, we need to count services and find the nearest service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge demographic data with zip code boundaries\n",
    "zip_gdf['zipCode'] = zip_gdf['zip'].astype(str)\n",
    "merged_gdf = zip_gdf.merge(acs_processed, on='zipCode', how='left')\n",
    "\n",
    "print(f\"Merged GeoDataFrame: {len(merged_gdf)} zip codes\")\n",
    "print(f\"With demographic data: {merged_gdf['population'].notna().sum()} zip codes\")\n",
    "\n",
    "# Create GeoDataFrame for services\n",
    "services_geometry = [Point(lng, lat) for lng, lat in zip(services_clean['lng'], services_clean['lat'])]\n",
    "services_gdf = gpd.GeoDataFrame(services_clean, geometry=services_geometry, crs='EPSG:4326')\n",
    "\n",
    "# Ensure same CRS\n",
    "merged_gdf = merged_gdf.to_crs('EPSG:4326')\n",
    "\n",
    "print(f\"Services GeoDataFrame: {len(services_gdf)} locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_service_metrics(zip_gdf, services_gdf):\n",
    "    \"\"\"\n",
    "    Calculate service count and nearest distance for each zip code\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for idx, zip_row in zip_gdf.iterrows():\n",
    "        zip_code = zip_row['zipCode']\n",
    "        zip_geom = zip_row.geometry\n",
    "        \n",
    "        if pd.isna(zip_row['population']) or zip_row['population'] == 0:\n",
    "            results.append({\n",
    "                'zipCode': zip_code,\n",
    "                'serviceCount': 0,\n",
    "                'nearestDistance': None\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Count services within zip code\n",
    "        services_in_zip = services_gdf[services_gdf.geometry.within(zip_geom)]\n",
    "        service_count = len(services_in_zip)\n",
    "        \n",
    "        # Calculate distance to nearest service\n",
    "        zip_centroid = zip_geom.centroid\n",
    "        \n",
    "        if len(services_gdf) > 0:\n",
    "            # Convert to projected CRS for distance calculation (meters)\n",
    "            temp_zip = gpd.GeoDataFrame([zip_centroid], columns=['geometry'], crs='EPSG:4326')\n",
    "            temp_services = services_gdf[['geometry']].copy()\n",
    "            \n",
    "            # Project to California State Plane for accurate distance\n",
    "            temp_zip_proj = temp_zip.to_crs('EPSG:3310')  # California Albers\n",
    "            temp_services_proj = temp_services.to_crs('EPSG:3310')\n",
    "            \n",
    "            distances = temp_services_proj.geometry.distance(temp_zip_proj.geometry.iloc[0])\n",
    "            nearest_distance_meters = distances.min()\n",
    "            nearest_distance_miles = nearest_distance_meters / 1609.34  # Convert to miles\n",
    "        else:\n",
    "            nearest_distance_miles = None\n",
    "        \n",
    "        results.append({\n",
    "            'zipCode': zip_code,\n",
    "            'serviceCount': service_count,\n",
    "            'nearestDistance': nearest_distance_miles\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Calculating service metrics for each zip code...\")\n",
    "service_metrics = calculate_service_metrics(merged_gdf, services_gdf)\n",
    "\n",
    "print(f\"\\nService Metrics Summary:\")\n",
    "print(f\"- Average services per zip: {service_metrics['serviceCount'].mean():.1f}\")\n",
    "print(f\"- Max services in one zip: {service_metrics['serviceCount'].max()}\")\n",
    "print(f\"- Zip codes with no services: {(service_metrics['serviceCount'] == 0).sum()}\")\n",
    "print(f\"- Average distance to nearest service: {service_metrics['nearestDistance'].mean():.1f} miles\")\n",
    "\n",
    "service_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Gap Scores and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all data together\n",
    "analysis_df = merged_gdf.merge(service_metrics, on='zipCode', how='left')\n",
    "\n",
    "# Calculate gap scores\n",
    "analysis_df['gapScore'] = analysis_df.apply(\n",
    "    lambda row: calculate_gap_score_current(\n",
    "        row['povertyRate'], \n",
    "        row['population'], \n",
    "        row['serviceCount'], \n",
    "        row['nearestDistance']\n",
    "    ) if pd.notna(row['population']) and row['population'] > 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter to valid data\n",
    "valid_data = analysis_df.dropna(subset=['gapScore', 'population', 'povertyRate'])\n",
    "\n",
    "print(f\"Gap Score Analysis:\")\n",
    "print(f\"- Valid zip codes: {len(valid_data)}\")\n",
    "print(f\"- Gap score range: {valid_data['gapScore'].min():.1f} - {valid_data['gapScore'].max():.1f}\")\n",
    "print(f\"- Average gap score: {valid_data['gapScore'].mean():.1f}\")\n",
    "print(f\"- High gap areas (>80): {(valid_data['gapScore'] > 80).sum()}\")\n",
    "\n",
    "# Show top 10 highest gap scores\n",
    "print(\"\\nTop 10 Highest Gap Scores:\")\n",
    "top_gaps = valid_data.nlargest(10, 'gapScore')[[\n",
    "    'zipCode', 'community', 'gapScore', 'povertyRate', 'population', \n",
    "    'serviceCount', 'nearestDistance'\n",
    "]]\n",
    "print(top_gaps.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Current Gap Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('San Diego Homelessness Service Gap Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Gap Score Distribution\n",
    "axes[0,0].hist(valid_data['gapScore'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].axvline(valid_data['gapScore'].mean(), color='red', linestyle='--', \n",
    "                  label=f'Mean: {valid_data[\"gapScore\"].mean():.1f}')\n",
    "axes[0,0].set_xlabel('Gap Score')\n",
    "axes[0,0].set_ylabel('Number of Zip Codes')\n",
    "axes[0,0].set_title('Distribution of Gap Scores')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Gap Score vs Poverty Rate\n",
    "scatter = axes[0,1].scatter(valid_data['povertyRate'], valid_data['gapScore'], \n",
    "                           c=valid_data['serviceCount'], cmap='viridis', alpha=0.7)\n",
    "axes[0,1].set_xlabel('Poverty Rate (%)')\n",
    "axes[0,1].set_ylabel('Gap Score')\n",
    "axes[0,1].set_title('Gap Score vs Poverty Rate\\n(Color = Service Count)')\n",
    "plt.colorbar(scatter, ax=axes[0,1], label='Service Count')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Service Count Distribution\n",
    "service_counts = valid_data['serviceCount'].value_counts().sort_index()\n",
    "axes[1,0].bar(service_counts.index, service_counts.values, alpha=0.7, color='lightcoral')\n",
    "axes[1,0].set_xlabel('Number of Services')\n",
    "axes[1,0].set_ylabel('Number of Zip Codes')\n",
    "axes[1,0].set_title('Distribution of Service Counts')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Distance vs Gap Score\n",
    "distance_data = valid_data.dropna(subset=['nearestDistance'])\n",
    "axes[1,1].scatter(distance_data['nearestDistance'], distance_data['gapScore'], \n",
    "                  alpha=0.6, color='orange')\n",
    "axes[1,1].set_xlabel('Distance to Nearest Service (miles)')\n",
    "axes[1,1].set_ylabel('Gap Score')\n",
    "axes[1,1].set_title('Gap Score vs Distance to Nearest Service')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Analysis\n",
    "\n",
    "Let's break down how each component contributes to the final score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_components(df):\n",
    "    \"\"\"\n",
    "    Calculate individual components of the gap score\n",
    "    \"\"\"\n",
    "    components = pd.DataFrame()\n",
    "    components['zipCode'] = df['zipCode']\n",
    "    \n",
    "    # Poverty component (0-50)\n",
    "    components['poverty_component'] = np.minimum(df['povertyRate'] * 2, 50)\n",
    "    \n",
    "    # Population component (0-25)\n",
    "    components['population_component'] = np.minimum((df['population'] / 1000) * 5, 25)\n",
    "    \n",
    "    # Service component (0-15)\n",
    "    components['service_component'] = np.maximum(15 - (df['serviceCount'] * 3), 0)\n",
    "    \n",
    "    # Distance component (0-10)\n",
    "    components['distance_component'] = np.where(\n",
    "        df['nearestDistance'].notna(),\n",
    "        np.minimum(df['nearestDistance'] * 2, 10),\n",
    "        10\n",
    "    )\n",
    "    \n",
    "    components['total_score'] = (\n",
    "        components['poverty_component'] + \n",
    "        components['population_component'] + \n",
    "        components['service_component'] + \n",
    "        components['distance_component']\n",
    "    )\n",
    "    \n",
    "    return components\n",
    "\n",
    "components_df = calculate_score_components(valid_data)\n",
    "\n",
    "# Component statistics\n",
    "print(\"Component Analysis:\")\n",
    "print(\"\\nAverage contribution by component:\")\n",
    "for col in ['poverty_component', 'population_component', 'service_component', 'distance_component']:\n",
    "    avg_contribution = components_df[col].mean()\n",
    "    pct_of_total = (avg_contribution / components_df['total_score'].mean()) * 100\n",
    "    print(f\"- {col.replace('_', ' ').title()}: {avg_contribution:.1f} points ({pct_of_total:.1f}% of total)\")\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\nComponent Correlations:\")\n",
    "correlation_matrix = components_df[[\n",
    "    'poverty_component', 'population_component', \n",
    "    'service_component', 'distance_component', 'total_score'\n",
    "]].corr()\n",
    "print(correlation_matrix.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize component contributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Service Gap Score Component Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "component_cols = ['poverty_component', 'population_component', 'service_component', 'distance_component']\n",
    "component_names = ['Poverty', 'Population', 'Service Availability', 'Geographic Access']\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "for i, (col, name, color) in enumerate(zip(component_cols, component_names, colors)):\n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.hist(components_df[col], bins=15, alpha=0.7, color=color, edgecolor='black')\n",
    "    ax.axvline(components_df[col].mean(), color='darkred', linestyle='--', \n",
    "               label=f'Mean: {components_df[col].mean():.1f}')\n",
    "    ax.set_xlabel('Score Points')\n",
    "    ax.set_ylabel('Number of Zip Codes')\n",
    "    ax.set_title(f'{name} Component Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stacked bar chart of components for top 15 zip codes\n",
    "top_15 = components_df.nlargest(15, 'total_score')\n",
    "top_15_with_names = top_15.merge(valid_data[['zipCode', 'community']], on='zipCode')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "bottom = np.zeros(len(top_15))\n",
    "\n",
    "for col, name, color in zip(component_cols, component_names, colors):\n",
    "    ax.bar(range(len(top_15)), top_15[col], bottom=bottom, label=name, color=color, alpha=0.8)\n",
    "    bottom += top_15[col]\n",
    "\n",
    "ax.set_xlabel('Zip Code')\n",
    "ax.set_ylabel('Gap Score Points')\n",
    "ax.set_title('Gap Score Components for Top 15 Highest-Need Zip Codes')\n",
    "ax.set_xticks(range(len(top_15)))\n",
    "ax.set_xticklabels([f\"{row['zipCode']}\\n({row['community']})\" for _, row in top_15_with_names.iterrows()], \n",
    "                   rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Scoring Algorithms\n",
    "\n",
    "Let's experiment with different weighting schemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gap_score_weighted(poverty_rate, population, service_count, nearest_distance, \n",
    "                                weights={'poverty': 0.4, 'population': 0.2, 'services': 0.25, 'distance': 0.15}):\n",
    "    \"\"\"\n",
    "    Alternative algorithm with configurable weights\n",
    "    \"\"\"\n",
    "    # Normalize each component to 0-1 scale\n",
    "    \n",
    "    # Poverty score (0-1, higher poverty = higher score)\n",
    "    poverty_score = min(poverty_rate / 50, 1.0)  # Cap at 50% poverty\n",
    "    \n",
    "    # Population score (0-1, more people = higher score)\n",
    "    population_score = min(population / 100000, 1.0)  # Cap at 100k population\n",
    "    \n",
    "    # Service score (0-1, fewer services = higher score)\n",
    "    if service_count >= 10:\n",
    "        service_score = 0\n",
    "    else:\n",
    "        service_score = (10 - service_count) / 10\n",
    "    \n",
    "    # Distance score (0-1, farther = higher score)\n",
    "    if nearest_distance is None:\n",
    "        distance_score = 1.0\n",
    "    else:\n",
    "        distance_score = min(nearest_distance / 10, 1.0)  # Cap at 10 miles\n",
    "    \n",
    "    # Weighted combination\n",
    "    final_score = (\n",
    "        poverty_score * weights['poverty'] +\n",
    "        population_score * weights['population'] +\n",
    "        service_score * weights['services'] +\n",
    "        distance_score * weights['distance']\n",
    "    )\n",
    "    \n",
    "    return final_score * 100  # Scale to 0-100\n",
    "\n",
    "def calculate_gap_score_equity_focused(poverty_rate, population, service_count, nearest_distance):\n",
    "    \"\"\"\n",
    "    Equity-focused algorithm that heavily weights poverty and access\n",
    "    \"\"\"\n",
    "    return calculate_gap_score_weighted(\n",
    "        poverty_rate, population, service_count, nearest_distance,\n",
    "        weights={'poverty': 0.6, 'population': 0.1, 'services': 0.2, 'distance': 0.1}\n",
    "    )\n",
    "\n",
    "def calculate_gap_score_capacity_focused(poverty_rate, population, service_count, nearest_distance):\n",
    "    \"\"\"\n",
    "    Capacity-focused algorithm that emphasizes population and services\n",
    "    \"\"\"\n",
    "    return calculate_gap_score_weighted(\n",
    "        poverty_rate, population, service_count, nearest_distance,\n",
    "        weights={'poverty': 0.2, 'population': 0.4, 'services': 0.3, 'distance': 0.1}\n",
    "    )\n",
    "\n",
    "# Calculate alternative scores\n",
    "valid_data['gapScore_weighted'] = valid_data.apply(\n",
    "    lambda row: calculate_gap_score_weighted(\n",
    "        row['povertyRate'], row['population'], row['serviceCount'], row['nearestDistance']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "valid_data['gapScore_equity'] = valid_data.apply(\n",
    "    lambda row: calculate_gap_score_equity_focused(\n",
    "        row['povertyRate'], row['population'], row['serviceCount'], row['nearestDistance']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "valid_data['gapScore_capacity'] = valid_data.apply(\n",
    "    lambda row: calculate_gap_score_capacity_focused(\n",
    "        row['povertyRate'], row['population'], row['serviceCount'], row['nearestDistance']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "print(\"Alternative Scoring Comparison:\")\n",
    "for col in ['gapScore', 'gapScore_weighted', 'gapScore_equity', 'gapScore_capacity']:\n",
    "    print(f\"{col}: mean={valid_data[col].mean():.1f}, std={valid_data[col].std():.1f}\")\n",
    "\n",
    "# Correlation between different scoring methods\n",
    "score_correlations = valid_data[[\n",
    "    'gapScore', 'gapScore_weighted', 'gapScore_equity', 'gapScore_capacity'\n",
    "]].corr()\n",
    "\n",
    "print(\"\\nCorrelations between scoring methods:\")\n",
    "print(score_correlations.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scoring methods visually\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Comparison of Gap Scoring Algorithms', fontsize=16, fontweight='bold')\n",
    "\n",
    "algorithms = [\n",
    "    ('gapScore', 'Current Algorithm'),\n",
    "    ('gapScore_weighted', 'Balanced Weighted'),\n",
    "    ('gapScore_equity', 'Equity-Focused'),\n",
    "    ('gapScore_capacity', 'Capacity-Focused')\n",
    "]\n",
    "\n",
    "for i, (col, title) in enumerate(algorithms):\n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.hist(valid_data[col], bins=20, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(valid_data[col].mean(), color='red', linestyle='--', \n",
    "               label=f'Mean: {valid_data[col].mean():.1f}')\n",
    "    ax.set_xlabel('Gap Score')\n",
    "    ax.set_ylabel('Number of Zip Codes')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot matrix\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "scatter_data = valid_data[['gapScore', 'gapScore_weighted', 'gapScore_equity', 'gapScore_capacity']]\n",
    "scatter_data.columns = ['Current', 'Weighted', 'Equity', 'Capacity']\n",
    "pd.plotting.scatter_matrix(scatter_data, alpha=0.6, figsize=(12, 10), diagonal='hist', ax=ax)\n",
    "plt.suptitle('Gap Score Method Correlations', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Analysis\n",
    "\n",
    "How do different algorithms rank zip codes differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rankings for each method\n",
    "ranking_data = valid_data[['zipCode', 'community', 'povertyRate', 'population', 'serviceCount']].copy()\n",
    "\n",
    "for col, name in algorithms:\n",
    "    ranking_data[f'{name}_rank'] = valid_data[col].rank(ascending=False, method='min')\n",
    "    ranking_data[f'{name}_score'] = valid_data[col]\n",
    "\n",
    "# Top 20 comparison\n",
    "print(\"Top 20 Zip Codes by Different Algorithms:\")\n",
    "print(\"\\nCurrent Algorithm Top 20:\")\n",
    "current_top20 = ranking_data[ranking_data['Current Algorithm_rank'] <= 20].sort_values('Current Algorithm_rank')\n",
    "print(current_top20[['zipCode', 'community', 'Current Algorithm_rank', 'Current Algorithm_score']].to_string(index=False))\n",
    "\n",
    "print(\"\\nEquity-Focused Algorithm Top 20:\")\n",
    "equity_top20 = ranking_data[ranking_data['Equity-Focused_rank'] <= 20].sort_values('Equity-Focused_rank')\n",
    "print(equity_top20[['zipCode', 'community', 'Equity-Focused_rank', 'Equity-Focused_score']].to_string(index=False))\n",
    "\n",
    "# Find zip codes that rank very differently\n",
    "ranking_data['rank_difference'] = abs(\n",
    "    ranking_data['Current Algorithm_rank'] - ranking_data['Equity-Focused_rank']\n",
    ")\n",
    "\n",
    "print(\"\\nZip codes with biggest ranking differences (Current vs Equity-Focused):\")\n",
    "big_differences = ranking_data.nlargest(10, 'rank_difference')[[\n",
    "    'zipCode', 'community', 'povertyRate', 'Current Algorithm_rank', \n",
    "    'Equity-Focused_rank', 'rank_difference'\n",
    "]]\n",
    "print(big_differences.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Analysis Functions\n",
    "\n",
    "Create functions to test custom weight combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_weights(poverty_weight=0.4, population_weight=0.2, \n",
    "                       service_weight=0.25, distance_weight=0.15):\n",
    "    \"\"\"\n",
    "    Test a custom weighting scheme\n",
    "    \"\"\"\n",
    "    # Ensure weights sum to 1\n",
    "    total_weight = poverty_weight + population_weight + service_weight + distance_weight\n",
    "    if abs(total_weight - 1.0) > 0.01:\n",
    "        print(f\"Warning: Weights sum to {total_weight:.3f}, normalizing...\")\n",
    "        poverty_weight /= total_weight\n",
    "        population_weight /= total_weight\n",
    "        service_weight /= total_weight\n",
    "        distance_weight /= total_weight\n",
    "    \n",
    "    weights = {\n",
    "        'poverty': poverty_weight,\n",
    "        'population': population_weight,\n",
    "        'services': service_weight,\n",
    "        'distance': distance_weight\n",
    "    }\n",
    "    \n",
    "    # Calculate scores\n",
    "    custom_scores = valid_data.apply(\n",
    "        lambda row: calculate_gap_score_weighted(\n",
    "            row['povertyRate'], row['population'], row['serviceCount'], \n",
    "            row['nearestDistance'], weights\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = valid_data[['zipCode', 'community', 'povertyRate', 'population', \n",
    "                         'serviceCount', 'nearestDistance']].copy()\n",
    "    results['customScore'] = custom_scores\n",
    "    results['rank'] = custom_scores.rank(ascending=False, method='min')\n",
    "    \n",
    "    print(f\"Custom Weights: Poverty={poverty_weight:.2f}, Population={population_weight:.2f}, \"\n",
    "          f\"Services={service_weight:.2f}, Distance={distance_weight:.2f}\")\n",
    "    print(f\"Score Statistics: Mean={custom_scores.mean():.1f}, Std={custom_scores.std():.1f}\")\n",
    "    \n",
    "    print(\"\\nTop 15 Zip Codes:\")\n",
    "    top_15 = results.nsmallest(15, 'rank')\n",
    "    print(top_15[['zipCode', 'community', 'customScore', 'rank']].to_string(index=False))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test some examples\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE 1: Poverty-Heavy Weighting\")\n",
    "print(\"=\" * 60)\n",
    "poverty_heavy = test_custom_weights(poverty_weight=0.7, population_weight=0.1, \n",
    "                                   service_weight=0.15, distance_weight=0.05)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXAMPLE 2: Service-Access Focused\")\n",
    "print(\"=\" * 60)\n",
    "access_focused = test_custom_weights(poverty_weight=0.3, population_weight=0.1, \n",
    "                                    service_weight=0.4, distance_weight=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis\n",
    "\n",
    "How sensitive are the results to parameter changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis():\n",
    "    \"\"\"\n",
    "    Test how small changes in weights affect rankings\n",
    "    \"\"\"\n",
    "    base_weights = {'poverty': 0.4, 'population': 0.2, 'services': 0.25, 'distance': 0.15}\n",
    "    \n",
    "    # Calculate base scores and rankings\n",
    "    base_scores = valid_data.apply(\n",
    "        lambda row: calculate_gap_score_weighted(\n",
    "            row['povertyRate'], row['population'], row['serviceCount'], \n",
    "            row['nearestDistance'], base_weights\n",
    "        ), axis=1\n",
    "    )\n",
    "    base_ranks = base_scores.rank(ascending=False, method='min')\n",
    "    \n",
    "    sensitivity_results = []\n",
    "    \n",
    "    # Test variations in each weight\n",
    "    for weight_name in base_weights.keys():\n",
    "        for delta in [-0.1, -0.05, 0.05, 0.1]:\n",
    "            test_weights = base_weights.copy()\n",
    "            test_weights[weight_name] += delta\n",
    "            \n",
    "            # Normalize other weights\n",
    "            remaining_weight = 1 - test_weights[weight_name]\n",
    "            other_weights = {k: v for k, v in base_weights.items() if k != weight_name}\n",
    "            other_total = sum(other_weights.values())\n",
    "            \n",
    "            for k in other_weights:\n",
    "                test_weights[k] = (other_weights[k] / other_total) * remaining_weight\n",
    "            \n",
    "            # Calculate new scores\n",
    "            test_scores = valid_data.apply(\n",
    "                lambda row: calculate_gap_score_weighted(\n",
    "                    row['povertyRate'], row['population'], row['serviceCount'], \n",
    "                    row['nearestDistance'], test_weights\n",
    "                ), axis=1\n",
    "            )\n",
    "            test_ranks = test_scores.rank(ascending=False, method='min')\n",
    "            \n",
    "            # Calculate rank correlation\n",
    "            rank_correlation = base_ranks.corr(test_ranks)\n",
    "            \n",
    "            # Count how many of top 20 changed\n",
    "            base_top20 = set(base_ranks[base_ranks <= 20].index)\n",
    "            test_top20 = set(test_ranks[test_ranks <= 20].index)\n",
    "            top20_overlap = len(base_top20.intersection(test_top20))\n",
    "            \n",
    "            sensitivity_results.append({\n",
    "                'weight_changed': weight_name,\n",
    "                'delta': delta,\n",
    "                'new_weight': test_weights[weight_name],\n",
    "                'rank_correlation': rank_correlation,\n",
    "                'top20_overlap': top20_overlap\n",
    "            })\n",
    "    \n",
    "    sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "    \n",
    "    print(\"Sensitivity Analysis Results:\")\n",
    "    print(\"(How much do rankings change with small weight adjustments?)\")\n",
    "    print()\n",
    "    \n",
    "    for weight in base_weights.keys():\n",
    "        weight_data = sensitivity_df[sensitivity_df['weight_changed'] == weight]\n",
    "        print(f\"\\n{weight.title()} Weight Sensitivity:\")\n",
    "        for _, row in weight_data.iterrows():\n",
    "            print(f\"  {row['delta']:+.2f} -> {row['new_weight']:.2f}: \"\n",
    "                  f\"Rank correlation = {row['rank_correlation']:.3f}, \"\n",
    "                  f\"Top-20 overlap = {row['top20_overlap']}/20\")\n",
    "    \n",
    "    return sensitivity_df\n",
    "\n",
    "sensitivity_results = sensitivity_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SAN DIEGO HOMELESSNESS SERVICE GAP ANALYSIS - SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä DATA OVERVIEW:\")\n",
    "print(f\"   ‚Ä¢ {len(valid_data)} zip codes analyzed\")\n",
    "print(f\"   ‚Ä¢ {len(services_clean)} homeless service locations\")\n",
    "print(f\"   ‚Ä¢ Poverty rates range: {valid_data['povertyRate'].min():.1f}% - {valid_data['povertyRate'].max():.1f}%\")\n",
    "print(f\"   ‚Ä¢ Population range: {valid_data['population'].min():,.0f} - {valid_data['population'].max():,.0f}\")\n",
    "\n",
    "print(f\"\\nüéØ CURRENT ALGORITHM PERFORMANCE:\")\n",
    "print(f\"   ‚Ä¢ Average gap score: {valid_data['gapScore'].mean():.1f}/100\")\n",
    "print(f\"   ‚Ä¢ High-need areas (>80): {(valid_data['gapScore'] > 80).sum()} zip codes\")\n",
    "print(f\"   ‚Ä¢ Top gap score: {valid_data['gapScore'].max():.1f} (Zip {valid_data.loc[valid_data['gapScore'].idxmax(), 'zipCode']})\")\n",
    "\n",
    "print(f\"\\nüèÜ HIGHEST NEED ZIP CODES (Current Algorithm):\")\n",
    "top_5_current = valid_data.nlargest(5, 'gapScore')\n",
    "for _, row in top_5_current.iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['zipCode']} ({row['community']}): {row['gapScore']:.1f} points\")\n",
    "    print(f\"     - Poverty: {row['povertyRate']:.1f}%, Population: {row['population']:,.0f}, Services: {row['serviceCount']}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è COMPONENT ANALYSIS:\")\n",
    "components = calculate_score_components(valid_data)\n",
    "total_avg = components['total_score'].mean()\n",
    "print(f\"   ‚Ä¢ Poverty component: {components['poverty_component'].mean():.1f} points ({components['poverty_component'].mean()/total_avg*100:.1f}% of total)\")\n",
    "print(f\"   ‚Ä¢ Population component: {components['population_component'].mean():.1f} points ({components['population_component'].mean()/total_avg*100:.1f}% of total)\")\n",
    "print(f\"   ‚Ä¢ Service component: {components['service_component'].mean():.1f} points ({components['service_component'].mean()/total_avg*100:.1f}% of total)\")\n",
    "print(f\"   ‚Ä¢ Distance component: {components['distance_component'].mean():.1f} points ({components['distance_component'].mean()/total_avg*100:.1f}% of total)\")\n",
    "\n",
    "print(f\"\\nüîÑ ALTERNATIVE ALGORITHMS:\")\n",
    "print(f\"   ‚Ä¢ Equity-focused (60% poverty weight):\")\n",
    "top_equity = valid_data.nlargest(3, 'gapScore_equity')\n",
    "for _, row in top_equity.iterrows():\n",
    "    print(f\"     - {row['zipCode']} ({row['community']}): {row['gapScore_equity']:.1f} points\")\n",
    "\n",
    "print(f\"\\n   ‚Ä¢ Capacity-focused (40% population weight):\")\n",
    "top_capacity = valid_data.nlargest(3, 'gapScore_capacity')\n",
    "for _, row in top_capacity.iterrows():\n",
    "    print(f\"     - {row['zipCode']} ({row['community']}): {row['gapScore_capacity']:.1f} points\")\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "print(f\"   ‚Ä¢ {(valid_data['serviceCount'] == 0).sum()} zip codes have NO homeless services\")\n",
    "print(f\"   ‚Ä¢ Average distance to nearest service: {valid_data['nearestDistance'].mean():.1f} miles\")\n",
    "print(f\"   ‚Ä¢ Poverty and gap scores are strongly correlated (r = {valid_data['povertyRate'].corr(valid_data['gapScore']):.2f})\")\n",
    "print(f\"   ‚Ä¢ Population size has moderate impact (r = {valid_data['population'].corr(valid_data['gapScore']):.2f})\")\n",
    "\n",
    "print(f\"\\nüéõÔ∏è TUNING RECOMMENDATIONS:\")\n",
    "print(f\"   ‚Ä¢ Current algorithm balances multiple factors well\")\n",
    "print(f\"   ‚Ä¢ For equity focus: Increase poverty weight to 0.6+\")\n",
    "print(f\"   ‚Ä¢ For capacity planning: Increase population weight to 0.4+\")\n",
    "print(f\"   ‚Ä¢ Algorithm is moderately sensitive to weight changes\")\n",
    "print(f\"   ‚Ä¢ Consider adding demographic factors (veterans, seniors, youth)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Save analysis results for further use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results dataset\n",
    "export_data = valid_data[[\n",
    "    'zipCode', 'community', 'population', 'povertyRate', \n",
    "    'serviceCount', 'nearestDistance', 'medianIncome'\n",
    "]].copy()\n",
    "\n",
    "export_data['gapScore_current'] = valid_data['gapScore']\n",
    "export_data['gapScore_equity'] = valid_data['gapScore_equity']\n",
    "export_data['gapScore_capacity'] = valid_data['gapScore_capacity']\n",
    "\n",
    "# Add component breakdowns\n",
    "components = calculate_score_components(valid_data)\n",
    "export_data['poverty_component'] = components['poverty_component']\n",
    "export_data['population_component'] = components['population_component']\n",
    "export_data['service_component'] = components['service_component']\n",
    "export_data['distance_component'] = components['distance_component']\n",
    "\n",
    "# Add rankings\n",
    "export_data['rank_current'] = valid_data['gapScore'].rank(ascending=False, method='min')\n",
    "export_data['rank_equity'] = valid_data['gapScore_equity'].rank(ascending=False, method='min')\n",
    "export_data['rank_capacity'] = valid_data['gapScore_capacity'].rank(ascending=False, method='min')\n",
    "\n",
    "# Save to CSV\n",
    "export_data.to_csv('service_gap_analysis_results.csv', index=False)\n",
    "print(\"Results exported to 'service_gap_analysis_results.csv'\")\n",
    "\n",
    "# Display sample of export data\n",
    "print(\"\\nSample of exported data:\")\n",
    "print(export_data.head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis complete! Check the exported CSV file for detailed results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}